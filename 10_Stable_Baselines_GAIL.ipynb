{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10_Stable_Baselines_GAIL.ipynb","provenance":[{"file_id":"1sWdW1ITHVsdvPrQpev5Sak9klobV6z4-","timestamp":1590356346490}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S8w9h5XbuMGv","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/drive/1WhiULuo9oBo1kKgXqQjNY53ht3J0TlEG?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n","\n","By [Ibrahim Sobh](https://www.linkedin.com/in/ibrahim-sobh-phd-8681757/)\n"]},{"cell_type":"markdown","metadata":{"id":"uzSsqB7Qymsj","colab_type":"text"},"source":["# GAIL [Generative Adversarial Imitation Learning](https://arxiv.org/pdf/1606.03476.pdf)\n","\n","In GANs [Generative Adversarial Networks](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), we have two networks learning together:\n","\n","- Generator network: try to fool the discriminator by generating real-looking images\n","- Discriminator network: try to distinguish between real and fake images\n","\n","### GAIL\n","GAIL uses a discriminator that tries to seperate expert trajectory from trajectories of the learned policy, which has the role of the generator here.\n","\n","### Steps\n","- Generate and save expert dataset\n","- Load the expert dataset\n","- Train GAIL agent and evaluate\n","\n"]},{"cell_type":"markdown","metadata":{"id":"X8MpsMtnyrk4","colab_type":"text"},"source":["## Install"]},{"cell_type":"code","metadata":{"id":"AK88-CxtIzwm","colab_type":"code","outputId":"6e9be094-f964-4291-c6d6-7e7ff7a592ab","executionInfo":{"status":"ok","timestamp":1582025105777,"user_tz":-120,"elapsed":26543,"user":{"displayName":"Ibrahim SOBH","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYeQM_1LvthZBu6TRjB85IH8s-a5ZMla2NYwtX=s64","userId":"05222794542711757573"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install gym\n","!pip install box2d-py\n","# !pip install pyglet==1.3.2\n","!pip install pyglet\n","!pip install stable-baselines\n","!pip install stable-baselines --upgrade"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.15.6)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.17.5)\n","Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.2.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym) (1.12.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.10)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n","Collecting box2d-py\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 7.9MB/s \n","\u001b[?25hInstalling collected packages: box2d-py\n","Successfully installed box2d-py-2.3.8\n","Requirement already satisfied: pyglet in /usr/local/lib/python3.6/dist-packages (1.4.10)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet) (0.16.0)\n","Requirement already satisfied: stable-baselines in /usr/local/lib/python3.6/dist-packages (2.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.17.5)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (4.1.2.30)\n","Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.15.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (3.1.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (4.28.1)\n","Requirement already satisfied: zmq in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.0.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.14.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.3.1.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (7.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.4.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.25.3)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.7)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.10.0)\n","Requirement already satisfied: mpi4py in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (3.0.3)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (3.38.0)\n","Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (1.12.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (1.4.10)\n","Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (0.2.6)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (6.2.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (2.4.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (2.6.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (1.1.0)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from zmq->stable-baselines) (17.0.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines) (2018.9)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->stable-baselines) (2.3.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (0.9.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (3.10.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.11.2)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.15.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.1.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (0.2.2)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (0.8.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (1.27.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (0.1.8)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines) (0.34.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (0.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines) (45.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.5.0->stable-baselines) (2.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.5.0->stable-baselines) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.5.0->stable-baselines) (3.2.1)\n","Collecting stable-baselines\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/05/f6651855083020c0363acf483450c23e38d96f5c18bec8bded113d528da5/stable_baselines-2.9.0-py3-none-any.whl (232kB)\n","\u001b[K     |████████████████████████████████| 235kB 8.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.14.1)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.25.3)\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (3.1.3)\n","Requirement already satisfied, skipping upgrade: cloudpickle>=0.5.5 in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.2.2)\n","Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (4.1.2.30)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.17.5)\n","Requirement already satisfied, skipping upgrade: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (0.15.6)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines) (1.4.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines) (2.6.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines) (2018.9)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (0.10.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (2.4.6)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines) (1.1.0)\n","Requirement already satisfied, skipping upgrade: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (1.4.10)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (1.12.0)\n","Requirement already satisfied, skipping upgrade: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (6.2.2)\n","Requirement already satisfied, skipping upgrade: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines) (0.2.6)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines) (45.1.0)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.10.9->stable-baselines) (0.16.0)\n","Installing collected packages: stable-baselines\n","  Found existing installation: stable-baselines 2.2.1\n","    Uninstalling stable-baselines-2.2.1:\n","      Successfully uninstalled stable-baselines-2.2.1\n","Successfully installed stable-baselines-2.9.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6NlznQ0_y2jv","colab_type":"text"},"source":["## Generate and save expert trajectories"]},{"cell_type":"code","metadata":{"id":"u6bC_jjPyfoC","colab_type":"code","outputId":"c983d719-2241-4691-9ddf-bbf9d0e90590","executionInfo":{"status":"ok","timestamp":1582025241126,"user_tz":-120,"elapsed":161845,"user":{"displayName":"Ibrahim SOBH","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYeQM_1LvthZBu6TRjB85IH8s-a5ZMla2NYwtX=s64","userId":"05222794542711757573"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Here is an example of training a Soft Actor-Critic model to generate expert trajectories for GAIL\n","# from stable_baselines import SAC\n","import gym\n","import numpy as np\n","from stable_baselines import TD3\n","from stable_baselines.td3.policies import MlpPolicy\n","from stable_baselines.common.vec_env import DummyVecEnv\n","from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n","from stable_baselines.gail import generate_expert_traj\n","\n","env = gym.make('Pendulum-v0')\n","env = DummyVecEnv([lambda: env])\n","\n","# The noise objects for TD3\n","n_actions = env.action_space.shape[-1]\n","action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n","model = TD3(MlpPolicy, env, action_noise=action_noise, verbose=1)\n","generate_expert_traj(model, 'expert_pendulum', n_timesteps=20000, n_episodes=10)\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:58: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:67: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:136: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/policies.py:125: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/sac/policies.py:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:169: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:199: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:313: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:313: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:214: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:242: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/td3/td3.py:245: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 4         |\n","| fps                     | 143       |\n","| mean 100 episode reward | -1.47e+03 |\n","| n_updates               | 400       |\n","| qf1_loss                | 2.8665037 |\n","| qf2_loss                | 2.272807  |\n","| time_elapsed            | 4         |\n","| total timesteps         | 600       |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 8         |\n","| fps                     | 152       |\n","| mean 100 episode reward | -1.42e+03 |\n","| n_updates               | 1200      |\n","| qf1_loss                | 1.6931641 |\n","| qf2_loss                | 1.5267487 |\n","| time_elapsed            | 9         |\n","| total timesteps         | 1400      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 12        |\n","| fps                     | 159       |\n","| mean 100 episode reward | -1.46e+03 |\n","| n_updates               | 2000      |\n","| qf1_loss                | 2.9583025 |\n","| qf2_loss                | 2.9583879 |\n","| time_elapsed            | 13        |\n","| total timesteps         | 2200      |\n","---------------------------------------\n","--------------------------------------\n","| current_lr              | 0.0003   |\n","| episodes                | 16       |\n","| fps                     | 160      |\n","| mean 100 episode reward | -1.5e+03 |\n","| n_updates               | 2800     |\n","| qf1_loss                | 9.928125 |\n","| qf2_loss                | 9.864404 |\n","| time_elapsed            | 18       |\n","| total timesteps         | 3000     |\n","--------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 20        |\n","| fps                     | 162       |\n","| mean 100 episode reward | -1.5e+03  |\n","| n_updates               | 3600      |\n","| qf1_loss                | 15.001545 |\n","| qf2_loss                | 14.903341 |\n","| time_elapsed            | 23        |\n","| total timesteps         | 3800      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 24        |\n","| fps                     | 162       |\n","| mean 100 episode reward | -1.48e+03 |\n","| n_updates               | 4400      |\n","| qf1_loss                | 21.0917   |\n","| qf2_loss                | 20.873962 |\n","| time_elapsed            | 28        |\n","| total timesteps         | 4600      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 28        |\n","| fps                     | 162       |\n","| mean 100 episode reward | -1.44e+03 |\n","| n_updates               | 5200      |\n","| qf1_loss                | 24.833828 |\n","| qf2_loss                | 24.764692 |\n","| time_elapsed            | 33        |\n","| total timesteps         | 5400      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 32        |\n","| fps                     | 163       |\n","| mean 100 episode reward | -1.4e+03  |\n","| n_updates               | 6000      |\n","| qf1_loss                | 31.556738 |\n","| qf2_loss                | 31.648472 |\n","| time_elapsed            | 37        |\n","| total timesteps         | 6200      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 36        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.34e+03 |\n","| n_updates               | 6800      |\n","| qf1_loss                | 56.18496  |\n","| qf2_loss                | 56.30286  |\n","| time_elapsed            | 42        |\n","| total timesteps         | 7000      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 40        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.3e+03  |\n","| n_updates               | 7600      |\n","| qf1_loss                | 57.712658 |\n","| qf2_loss                | 57.84614  |\n","| time_elapsed            | 47        |\n","| total timesteps         | 7800      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 44        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.26e+03 |\n","| n_updates               | 8400      |\n","| qf1_loss                | 56.995678 |\n","| qf2_loss                | 56.85033  |\n","| time_elapsed            | 52        |\n","| total timesteps         | 8600      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 48        |\n","| fps                     | 165       |\n","| mean 100 episode reward | -1.23e+03 |\n","| n_updates               | 9200      |\n","| qf1_loss                | 78.26182  |\n","| qf2_loss                | 77.88378  |\n","| time_elapsed            | 56        |\n","| total timesteps         | 9400      |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 52        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.19e+03 |\n","| n_updates               | 10000     |\n","| qf1_loss                | 80.80955  |\n","| qf2_loss                | 80.132126 |\n","| time_elapsed            | 61        |\n","| total timesteps         | 10200     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 56        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.17e+03 |\n","| n_updates               | 10800     |\n","| qf1_loss                | 72.177795 |\n","| qf2_loss                | 71.89429  |\n","| time_elapsed            | 66        |\n","| total timesteps         | 11000     |\n","---------------------------------------\n","----------------------------------------\n","| current_lr              | 0.0003     |\n","| episodes                | 60         |\n","| fps                     | 164        |\n","| mean 100 episode reward | -1.16e+03  |\n","| n_updates               | 11600      |\n","| qf1_loss                | 111.096016 |\n","| qf2_loss                | 110.92623  |\n","| time_elapsed            | 71         |\n","| total timesteps         | 11800      |\n","----------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 64        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.16e+03 |\n","| n_updates               | 12400     |\n","| qf1_loss                | 137.1511  |\n","| qf2_loss                | 136.90508 |\n","| time_elapsed            | 76        |\n","| total timesteps         | 12600     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 68        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.16e+03 |\n","| n_updates               | 13200     |\n","| qf1_loss                | 85.43174  |\n","| qf2_loss                | 85.38483  |\n","| time_elapsed            | 81        |\n","| total timesteps         | 13400     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 72        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.15e+03 |\n","| n_updates               | 14000     |\n","| qf1_loss                | 108.34826 |\n","| qf2_loss                | 108.13051 |\n","| time_elapsed            | 86        |\n","| total timesteps         | 14200     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 76        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.14e+03 |\n","| n_updates               | 14800     |\n","| qf1_loss                | 135.7918  |\n","| qf2_loss                | 135.50346 |\n","| time_elapsed            | 91        |\n","| total timesteps         | 15000     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 80        |\n","| fps                     | 165       |\n","| mean 100 episode reward | -1.13e+03 |\n","| n_updates               | 15600     |\n","| qf1_loss                | 182.70837 |\n","| qf2_loss                | 182.33917 |\n","| time_elapsed            | 95        |\n","| total timesteps         | 15800     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 84        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.12e+03 |\n","| n_updates               | 16400     |\n","| qf1_loss                | 190.71883 |\n","| qf2_loss                | 190.17444 |\n","| time_elapsed            | 100       |\n","| total timesteps         | 16600     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 88        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.1e+03  |\n","| n_updates               | 17200     |\n","| qf1_loss                | 163.29416 |\n","| qf2_loss                | 162.7019  |\n","| time_elapsed            | 105       |\n","| total timesteps         | 17400     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 92        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.09e+03 |\n","| n_updates               | 18000     |\n","| qf1_loss                | 142.35443 |\n","| qf2_loss                | 142.33186 |\n","| time_elapsed            | 110       |\n","| total timesteps         | 18200     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 96        |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.07e+03 |\n","| n_updates               | 18800     |\n","| qf1_loss                | 153.52393 |\n","| qf2_loss                | 153.3979  |\n","| time_elapsed            | 115       |\n","| total timesteps         | 19000     |\n","---------------------------------------\n","---------------------------------------\n","| current_lr              | 0.0003    |\n","| episodes                | 100       |\n","| fps                     | 164       |\n","| mean 100 episode reward | -1.06e+03 |\n","| n_updates               | 19600     |\n","| qf1_loss                | 226.97789 |\n","| qf2_loss                | 227.14795 |\n","| time_elapsed            | 120       |\n","| total timesteps         | 19800     |\n","---------------------------------------\n","actions (2000, 1)\n","obs (2000, 3)\n","rewards (2000,)\n","episode_returns (10,)\n","episode_starts (2000,)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'actions': array([[-0.6231084 ],\n","        [-0.61850584],\n","        [-0.62992656],\n","        ...,\n","        [-1.7786973 ],\n","        [-1.9231621 ],\n","        [-1.9736314 ]], dtype=float32),\n"," 'episode_returns': array([-639.91789679, -767.61171303, -742.2489131 , -503.10143113,\n","        -780.40580989, -768.87662937, -789.46892238, -763.61080178,\n","        -765.05994363, -528.3228281 ]),\n"," 'episode_starts': array([ True, False, False, ..., False, False, False]),\n"," 'obs': array([[ 0.99738544,  0.0722651 ,  0.34185213],\n","        [ 0.99617803,  0.08734594,  0.3025847 ],\n","        [ 0.9948813 ,  0.10105053,  0.27531826],\n","        ...,\n","        [ 0.6024808 , -0.7981334 , -3.8638847 ],\n","        [ 0.3987389 , -0.9170645 , -4.7292895 ],\n","        [ 0.12453896, -0.99221474, -5.705562  ]], dtype=float32),\n"," 'rewards': array([-0.01730591, -0.01718709, -0.01822298, ..., -2.35025263,\n","        -3.58743644, -5.34996176])}"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"2CHgyweZ6MnY","colab_type":"code","colab":{}},"source":["results_mean_list = []\n","results_std_list = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ILV7Xq665gwZ","colab_type":"code","outputId":"6e831000-0dfd-4f0c-fe2e-f84a5f6ebf48","executionInfo":{"status":"ok","timestamp":1582025250197,"user_tz":-120,"elapsed":170893,"user":{"displayName":"Ibrahim SOBH","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYeQM_1LvthZBu6TRjB85IH8s-a5ZMla2NYwtX=s64","userId":"05222794542711757573"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["# Evalaute the TD3 model (which generated the trajectories) \n","env = model.get_env()\n","obs = env.reset()\n","r_list = []\n","\n","for i in range(10):\n","  print(\"\\riteration: {}\".format(i), end=\"\")\n","  reward_sum = 0.0\n","  for _ in range(1000):\n","\n","          action, _ = model.predict(obs)\n","          obs, reward, done, _ = env.step(action)\n","          reward_sum += reward\n","          if done:\n","                  r_list.append(reward_sum)\n","                  reward_sum = 0.0\n","                  obs = env.reset()\n","\n","print('\\nmean, std')\n","print(np.mean(r_list), np.std(r_list))\n","results_mean_list.append(np.mean(r_list))\n","results_std_list.append(np.std(r_list)) \n","env.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["iteration: 9\n","mean, std\n","-722.691918814492 111.12368136240866\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4_cL6yu5y7l2","colab_type":"text"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"Cf1Xuk677cDb","colab_type":"code","colab":{}},"source":["n_steps = 0\n","\n","def callback(_locals, _globals):\n","    global n_steps\n","    print(\"\\r Steps: {}\".format(n_steps), end = \"\")\n","    n_steps += 1\n","    return True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"67BI65Q1sWoS","colab_type":"code","outputId":"e78e63ef-0341-4f69-8df0-6e3f50097496","executionInfo":{"status":"ok","timestamp":1582026917747,"user_tz":-120,"elapsed":1838414,"user":{"displayName":"Ibrahim SOBH","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYeQM_1LvthZBu6TRjB85IH8s-a5ZMla2NYwtX=s64","userId":"05222794542711757573"}},"colab":{"base_uri":"https://localhost:8080/","height":526}},"source":["from stable_baselines import GAIL, SAC\n","from stable_baselines.gail import ExpertDataset, generate_expert_traj\n","# Load the expert dataset\n","dataset = ExpertDataset(expert_path='expert_pendulum.npz', traj_limitation=10, verbose=1)\n","\n","model = GAIL(\"MlpPolicy\", 'Pendulum-v0', dataset, verbose=0)\n","# Note: in practice, you need to train for 1M steps to have a working policy\n","model.learn(total_timesteps=200000, callback=callback)\n","model.save(\"gail_pendulum\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["actions (2000, 1)\n","obs (2000, 3)\n","rewards (2000,)\n","episode_returns (10,)\n","episode_starts (2000,)\n","Total trajectories: 10\n","Total transitions: 2000\n","Average returns: -704.8624889178202\n","Std for returns: 102.69602528313158\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/mpi_running_mean_std.py:17: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/mpi_running_mean_std.py:42: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/gail/adversary.py:116: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/gail/adversary.py:99: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n","  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:108: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/common/tf_util.py:109: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"," Steps: 0WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/gail/adversary.py:153: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/stable_baselines/trpo_mpi/trpo_mpi.py:358: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.\n","\n"," Steps: 196"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vAcju460L-54","colab_type":"text"},"source":["## Evaluate "]},{"cell_type":"code","metadata":{"id":"q5iq_eE-M3Or","colab_type":"code","outputId":"6e1f0c6b-0200-4a99-a8d7-439378b5e129","executionInfo":{"status":"ok","timestamp":1582028337465,"user_tz":-120,"elapsed":17269,"user":{"displayName":"Ibrahim SOBH","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAYeQM_1LvthZBu6TRjB85IH8s-a5ZMla2NYwtX=s64","userId":"05222794542711757573"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["env = model.get_env()\n","obs = env.reset()\n","r_list = []\n","\n","for i in range(10):\n","  print(\"\\riteration: {}\".format(i), end=\"\")\n","  reward_sum = 0.0\n","  for _ in range(1000):\n","\n","          action, _ = model.predict(obs)\n","          obs, reward, done, _ = env.step(action)\n","          reward_sum += reward\n","          if done:\n","                  r_list.append(reward_sum)\n","                  reward_sum = 0.0\n","                  obs = env.reset()\n","\n","print('\\nmean, std')\n","print(np.mean(r_list), np.std(r_list))\n","results_mean_list.append(np.mean(r_list))\n","results_std_list.append(np.std(r_list)) \n","env.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["iteration: 9\n","mean, std\n","-932.6035695613036 173.95717308774894\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XoldUpdZ5jhN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}